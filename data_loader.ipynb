{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_loader.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPr6/mpnDzSYh8lTZhO5anw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"iCMQ0mxfhIM5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1596276135093,"user_tz":-480,"elapsed":21434,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"11076877845168992135"}},"outputId":"62a5befc-48a7-481a-fc5c-30aded802bba"},"source":["# 挂载google drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","# 切换工作路径\n","import os\n","os.chdir(\"/content/drive/My Drive/Colab/WaterMapping/Github_upload\")\n","# !ls\n","# !nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G4i23YHslpWw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1596276140314,"user_tz":-480,"elapsed":4619,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"11076877845168992135"}},"outputId":"cd998472-778b-42f6-82a0-f864e8ddf71d"},"source":["try:\n","    # %tensorflow_version only exists in Colab.\n","    %tensorflow_version 2.x\n","except Exception:\n","    pass\n","import tensorflow as tf\n","import numpy as np\n","import random\n","import pathlib\n","from utils import readTiff"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","convert_py.ipynb   model.ipynb\t     test_image_demo  utils.py\n","data_loader.ipynb  pretrained_model  trainer.ipynb\n","infer_demo.ipynb   __pycache__\t     utils.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7thsz4ZRIlcK","colab_type":"code","colab":{}},"source":["folder_TrainScenes = '/content/drive/My Drive/Colab/WaterMapping/TrainingData/TrainingScene/' \n","folder_TrainTruths = '/content/drive/My Drive/Colab/WaterMapping/TrainingData/TrainingTruth/'\n","PATCH_SIZE = 512\n","BATCH_SIZE = 4\n","BUFFER_SIZE = 200"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e-bHEH7LlyPF","colab_type":"code","colab":{}},"source":["###  Get the pathes (string) corresponding to image pathes, return a list\n","def get_path(folder_Scenes, folder_Truths):    \n","    path_Scenes = pathlib.Path(folder_Scenes)\n","    path_Truths = pathlib.Path(folder_Truths)\n","    Scene_paths = list(path_Scenes.glob('*'))\n","    Scene_paths = sorted([str(path) for path in Scene_paths])    \n","    Truth_paths = list(path_Truths.glob('*'))\n","    Truth_paths = sorted([str(path) for path in Truth_paths])\n","    return Scene_paths, Truth_paths\n","\n","### load the scenes\n","def load_scene(Scene_paths, Truth_paths, Patch_size):\n","    Scenes = list(range(len(Scene_paths)))   ## initialized the list\n","    Truths = list(range(len(Scene_paths)))\n","    Radios = list(range(len(Scene_paths)))  \n","    for i in range(len(Scene_paths)):\n","        Scenes[i], _, _, im_row,im_col, _ = readTiff(Scene_paths[i])\n","        Truths[i], _, _, _, _, _ = readTiff(Truth_paths[i])\n","        Truths[i] = np.expand_dims(Truths[i], axis=2)\n","        Radios[i] = (im_row//Patch_size+1)*(im_col//Patch_size+1)\n","    return Scenes, Truths, Radios\n","\n","#### Data augmentation: noisy, filp, rotate, data missing. \n","def Image_aug(scene, truth, flip = True, rot = True, noisy = True, missing = True):\n","    scene_aug = np.copy(scene)\n","    truth_aug = np.copy(truth)\n","    if noisy == True:\n","        if np.random.uniform(()) > 0.5:  \n","            noise = np.random.normal(loc = 0, scale = 0.01, size = (512, 512, scene.shape[2]))\n","            scene_aug = scene_aug + noise            \n","    if missing == True:\n","        if np.random.uniform(()) > 0.75: \n","            missing_wigth_row = random.randint(0,10)\n","            missing_wigth_col = random.randint(0,10)\n","            row_start = random.randint(0,scene_aug.shape[0]-missing_wigth_row)\n","            col_start = random.randint(0,scene_aug.shape[1]-missing_wigth_col)    \n","            scene_aug[row_start:row_start+missing_wigth_row, :, :] = 0\n","            scene_aug[:, col_start:col_start+missing_wigth_col, :] = 0\n","    if flip == True:\n","        if np.random.uniform(()) > 0.5:\n","            if random.randint(1,2) == 1:  ## horizontal or vertical mirroring\n","                scene_aug = np.flip(scene_aug, 1)\n","                truth_aug = np.flip(truth_aug, 1)\n","            else: \n","                scene_aug = np.flip(scene_aug, 0)\n","                truth_aug = np.flip(truth_aug, 0)\n","    if rot == True:\n","        if np.random.uniform(()) > 0.5:  \n","            degree = random.randint(1,3)\n","            scene_aug = np.rot90(scene_aug, k=degree)\n","            truth_aug = np.rot90(truth_aug, k=degree)\n","    return scene_aug.astype(np.float32), truth_aug.astype(np.float32)\n","\n","## crop the scenes to patches\n","def random_crop(input_scenes, real_scenes, radios, Patch_size):\n","    n_band = input_scenes[0].shape[2]\n","    PatchSet = []\n","    TruthSet = []\n","    for i in range(len(input_scenes)):    \n","        for j in range(radios[i]):\n","            random_row = random.randint(0,input_scenes[i].shape[0]-Patch_size)\n","            random_col = random.randint(0,input_scenes[i].shape[1]-Patch_size)\n","            stacked_scenes = np.concatenate([input_scenes[i], real_scenes[i]], axis=2).astype(np.float32)\n","            cropped_scenes = stacked_scenes[random_row:random_row+Patch_size, random_col:random_col+Patch_size, :]\n","            PatchSet.append(cropped_scenes[:,:,0:n_band])\n","            TruthSet.append(cropped_scenes[:,:,n_band:n_band+1])\n","    return PatchSet, TruthSet \n","\n","def get_scene(folder_Scenes, folder_Truths, PATCH_SIZE):\n","    ## input the path of the folders corresponding to scenes and truth\n","    path_Scenes, path_Truths = get_path(folder_Scenes, folder_Truths)\n","    Scenes, Truths, Ratios = load_scene(path_Scenes, path_Truths, PATCH_SIZE)\n","    Scenes = [np.clip(Scenes/10000, 0, 1) for Scenes in Scenes]  #   Normalization\n","    return Scenes, Truths\n","\n","def get_patch(Scenes, Truths, BATCH_SIZE, BUFFER_SIZE):\n","    ## input Scenes and Truths are the list datatype\n","    ## return tf.data.Dataset\n","    Crop_Ratios = np.ones(len(Scenes), dtype=np.int)\n","    Patches, PatchTruths = random_crop(Scenes, Truths, \n","                            radios=Crop_Ratios, Patch_size=PATCH_SIZE)\n","    # data augmentation\n","    Patches_aug = np.zeros((len(Patches), Patches[0].shape[0],\n","                                Patches[0].shape[1], Patches[0].shape[2]))\n","    PatchTruths_aug = np.zeros((len(PatchTruths), PatchTruths[0].shape[0], \n","                                PatchTruths[0].shape[1], PatchTruths[0].shape[2]))\n","    for i in range(len(Patches)):\n","        Patches_aug[i], PatchTruths_aug[i] = Image_aug(Patches[i], PatchTruths[i], \n","                            flip = True, rot = True, noisy = True, missing = False)       \n","    dataSet = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(Patches_aug), \n","                                    tf.convert_to_tensor(PatchTruths_aug)))\n","    dataSet = dataSet.batch(BATCH_SIZE).shuffle(BUFFER_SIZE)\n","    return dataSet\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WzKz_JRZr0a4","colab_type":"code","colab":{}},"source":["# Scenes, Truths = get_scene(folder_TrainScenes, folder_TrainTruths, PATCH_SIZE)\n","# TrainSet = get_patch(Scenes, Truths, BATCH_SIZE, BUFFER_SIZE)\n","# TrainSet"],"execution_count":null,"outputs":[]}]}